{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Linear model with Estimators\" and info about tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "x = np.random.sample((100,2))\n",
    "# make a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x).batch(BATCH_SIZE)\n",
    "\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st:\n",
      "[[0.29056874 0.61646245]\n",
      " [0.71409457 0.61134421]\n",
      " [0.40056018 0.88109308]\n",
      " [0.41715577 0.83150932]]\n",
      "2nd:\n",
      "[[0.72923825 0.776149  ]\n",
      " [0.85322457 0.26545222]\n",
      " [0.33889616 0.84120499]\n",
      " [0.08851575 0.68703991]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # doesn't work when eager_execution is on\n",
    "    print(\"1st:\")\n",
    "    print(sess.run(el)) \n",
    "    print(\"2nd:\")\n",
    "    print(sess.run(el)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the number of times we want the dataset to be iterated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCHING\n",
    "BATCH_SIZE = 4\n",
    "x = np.array([[1],[2],[3],[4]])\n",
    "# make a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset = dataset.shuffle(buffer_size=100)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [3]\n",
      " [2]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # doesn't work when eager_execution is on\n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict(df)[\"col1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.sample((100,2))\n",
    "y = np.random.sample((100,1))\n",
    "# make a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((2,), (1,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.11510448 0.90050657], shape=(2,), dtype=float64)\n",
      "tf.Tensor([0.92966304], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in dataset.take(1):\n",
    "    print(feature_batch)\n",
    "    print(label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=x)\n",
    "y = {'output': [1, 2]}\n",
    "df_labels = pd.DataFrame(data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, df_labels.values)) # what the fuck? How to do it without values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((2,), (1,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EagerTensor' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-5d3b1ebf1e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output 1 as there is in new ds only one example\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EagerTensor' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in dataset.take(1):\n",
    "    print(type(feature_batch.keys()))\n",
    "    print(type(list(feature_batch.keys())))\n",
    "    print(type(feature_batch))\n",
    "    print(feature_batch['col1']) # output 1 as there is in new ds only one example\n",
    "    print(label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'status': ['broke', 'middle', 'rich', 'rapper', 'rapper', 'rich'],\n",
    "     'col2': [3, 4, 4, 5, 6, 7], \n",
    "     'age':[12, 20, 24, 27, 40, 65]}\n",
    "y = {'output': [1, 2, 3, 4, 5, 6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature_batch, label_batch in ds.take(1):\n",
    "#   print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col2 = fc.numeric_column('col2')\n",
    "fc.input_layer(x, [col2]).numpy() # what does it do? Just input tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fc.categorical_column_with_vocabulary_list(\n",
    "    'status',\n",
    "    ['broke', 'middle', 'rich', 'rapper']) # asossiate 0 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1018, shape=(6, 5), dtype=float32, numpy=\n",
       "array([[3., 1., 0., 0., 0.],\n",
       "       [4., 0., 1., 0., 0.],\n",
       "       [4., 0., 0., 1., 0.],\n",
       "       [5., 0., 0., 0., 1.],\n",
       "       [6., 0., 0., 0., 1.],\n",
       "       [7., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.input_layer(x # is equal to feature batch\n",
    "               , [col2, fc.indicator_column(status)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Columns with Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we don't know the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_hash = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'status', hash_bucket_size=5) # why does it sometimes have the same values for different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_result = fc.input_layer(x, [fc.indicator_column(status_hash)])\n",
    "print(status_result.numpy().shape)\n",
    "status_result.numpy() # hash code one-hot vector for every class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 4, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(status_result, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketized columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use boundaries and ranges  instead of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = fc.numeric_column('age')\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: id=1126, shape=(6, 4), dtype=float32, numpy=\n",
       "array([[12.,  1.,  0.,  0.],\n",
       "       [20.,  0.,  1.,  0.],\n",
       "       [24.,  0.,  1.,  0.],\n",
       "       [27.,  0.,  1.,  0.],\n",
       "       [40.,  0.,  0.,  1.],\n",
       "       [65.,  0.,  0.,  1.]], dtype=float32)>>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.input_layer(x, [age, age_buckets]).numpy # 3 ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7th' 'pro']\n",
      " ['8th' 'sport']\n",
      " ['10th' 'sci']\n",
      " ['10th' 'model']\n",
      " ['6th' 'pro']\n",
      " ['1th' 'tech']]\n"
     ]
    }
   ],
   "source": [
    "x = {'education': ['7th', '8th', '10th', '10th', '6th', '1th'],\n",
    "     'occupation': ['pro', 'sport', 'sci', 'model', 'pro', 'tech'],}\n",
    "x = pd.DataFrame(data = x)\n",
    "y = {'output': [1, 2, 3, 4, 5, 6]}\n",
    "y = pd.DataFrame(data = y)\n",
    "print(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = fc.categorical_column_with_vocabulary_list(\n",
    "    'education',\n",
    "    ['7th', '8th', '10th', '6th', '1th'])\n",
    "occupation = fc.categorical_column_with_vocabulary_list(\n",
    "    'occupation',\n",
    "    ['pro', 'sport', 'sci', 'model', 'tech'])\n",
    "\n",
    "#education = fc.indicator_column(education)\n",
    "\n",
    "#occupation = fc.indicator_column(occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_x_occupation = tf.feature_column.crossed_column(\n",
    "    ['education', 'occupation'], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which method is correct?\n",
    "#education_x_occupation  = tf.feature_column.crossed_column(\n",
    "#    [education, occupation], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CrossedColumn(keys=(_VocabularyListCategoricalColumn(key='education', vocabulary_list=('7th', '8th', '10th', '6th', '1th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='occupation', vocabulary_list=('pro', 'sport', 'sci', 'model', 'tech'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=30, hash_key=None)\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [\n",
    "    education,\n",
    "    occupation,\n",
    "    education_x_occupation]\n",
    "print(education_x_occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: _VocabularyListCategoricalColumn(key='education', vocabulary_list=('7th', '8th', '10th', '6th', '1th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-86398692f8fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[0;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[1;32m--> 277\u001b[1;33m                                trainable, cols_to_vars)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[0;32m    179\u001b[0m           \u001b[1;34m'Items of feature_columns must be a _DenseColumn. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m           \u001b[1;34m'You can wrap a categorical column with an '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m           'embedding_column or indicator_column. Given: {}'.format(column))\n\u001b[0m\u001b[0;32m    182\u001b[0m   \u001b[0mweight_collections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_collections\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweight_collections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: _VocabularyListCategoricalColumn(key='education', vocabulary_list=('7th', '8th', '10th', '6th', '1th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
     ]
    }
   ],
   "source": [
    "fc.input_layer(x, feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-01861d1f1ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     fc.indicator_column(education_x_occupation)]\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mexample_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_cols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[0;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[1;32m--> 277\u001b[1;33m                                trainable, cols_to_vars)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[0;32m    189\u001b[0m   \u001b[1;31m# is wrapped by a `make_template`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m   with variable_scope.variable_scope(\n\u001b[1;32m--> 191\u001b[1;33m       scope, default_name='input_layer', values=features.values()):\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[0mbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LazyBuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# From stackoverflow\n",
    "feat_cols = [\n",
    "    #fc.indicator_column(education),\n",
    "    #fc.indicator_column(occupation),\n",
    "    fc.indicator_column(education_x_occupation)]\n",
    "\n",
    "example_data = fc.input_layer(x, feat_cols) # output\n",
    "print(example_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Nuclear\\AppData\\Local\\Temp\\tmp8gfumv_6\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_service': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022BAD947D30>, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_master': '', '_device_fn': None, '_task_id': 0, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_train_distribute': None, '_session_config': None, '_task_type': 'worker', '_evaluation_master': '', '_model_dir': 'C:\\\\Users\\\\Nuclear\\\\AppData\\\\Local\\\\Temp\\\\tmp8gfumv_6'}\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feat_cols,\n",
    "        hidden_units=[2, 10],\n",
    "        n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(x)\n",
    "a =df[0:3].copy()\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lambda test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lambda: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "def sqrt_(x):\n",
    "    return np.sqrt(x)\n",
    "\n",
    "fun = lambda: sqrt_(x) # function with no argument\n",
    "\n",
    "x = 3\n",
    "print(fun()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult3 = filter(lambda x: x % 3 == 0, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "list(mult3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def transform(n):\n",
    "     return lambda x: x + n\n",
    "\n",
    "f = transform(3)\n",
    "print(f(4))\n",
    "print(transform(3)(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>50K', '<=50K', '<=50K', '>50K', '>50K'], dtype='<U5')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.array(['<=50K', '>50K'])\n",
    "pred_class_id = [1, 0,0, 1, 1]\n",
    "classes[np.array(pred_class_id)] # the same as clsses[i] where i = 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
